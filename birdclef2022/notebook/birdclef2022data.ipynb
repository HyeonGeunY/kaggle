{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/skang/Documents/kaggle/bird_clef/notebook\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/skang/Documents/kaggle/bird_clef/notebook'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd /home/skang/Documents/kaggle/bird_clef/notebook\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import random\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../input/birdclef-2022/\"\n",
    "input_path = root_path + '/train_audio/'\n",
    "out_path = \"./train/\"\n",
    "\n",
    "meta_df = pd.read_csv(root_path + 'train_metadata.csv')\n",
    "bird_label = list(meta_df[\"primary_label\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df['filepath'] = input_path + \"/\" + meta_df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        afrsil1/XC125458.ogg\n",
       "1        afrsil1/XC175522.ogg\n",
       "2        afrsil1/XC177993.ogg\n",
       "3        afrsil1/XC205893.ogg\n",
       "4        afrsil1/XC207431.ogg\n",
       "                 ...         \n",
       "14847     zebdov/XC629769.ogg\n",
       "14848     zebdov/XC642415.ogg\n",
       "14849     zebdov/XC665873.ogg\n",
       "14850     zebdov/XC666194.ogg\n",
       "14851     zebdov/XC666195.ogg\n",
       "Name: filename, Length: 14852, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {filename: str('test') + \"/\" + filename for filename in meta_df.filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make essential (label, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_label = list(meta_df['primary_label'].unique())\n",
    "essentials= {\"birds\": bird_label, \"sample_rate\": 32000}\n",
    "with open(\"test.json\", \"w\") as f:\n",
    "    json.dump(essentials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\") as f:\n",
    "    essentials = json.load(f)\n",
    "\n",
    "mapping = list(essentials['birds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afrsil1',\n",
       " 'akekee',\n",
       " 'akepa1',\n",
       " 'akiapo',\n",
       " 'akikik',\n",
       " 'amewig',\n",
       " 'aniani',\n",
       " 'apapan',\n",
       " 'arcter',\n",
       " 'barpet',\n",
       " 'bcnher',\n",
       " 'belkin1',\n",
       " 'bkbplo',\n",
       " 'bknsti',\n",
       " 'bkwpet',\n",
       " 'blkfra',\n",
       " 'blknod',\n",
       " 'bongul',\n",
       " 'brant',\n",
       " 'brnboo',\n",
       " 'brnnod',\n",
       " 'brnowl',\n",
       " 'brtcur',\n",
       " 'bubsan',\n",
       " 'buffle',\n",
       " 'bulpet',\n",
       " 'burpar',\n",
       " 'buwtea',\n",
       " 'cacgoo1',\n",
       " 'calqua',\n",
       " 'cangoo',\n",
       " 'canvas',\n",
       " 'caster1',\n",
       " 'categr',\n",
       " 'chbsan',\n",
       " 'chemun',\n",
       " 'chukar',\n",
       " 'cintea',\n",
       " 'comgal1',\n",
       " 'commyn',\n",
       " 'compea',\n",
       " 'comsan',\n",
       " 'comwax',\n",
       " 'coopet',\n",
       " 'crehon',\n",
       " 'dunlin',\n",
       " 'elepai',\n",
       " 'ercfra',\n",
       " 'eurwig',\n",
       " 'fragul',\n",
       " 'gadwal',\n",
       " 'gamqua',\n",
       " 'glwgul',\n",
       " 'gnwtea',\n",
       " 'golphe',\n",
       " 'grbher3',\n",
       " 'grefri',\n",
       " 'gresca',\n",
       " 'gryfra',\n",
       " 'gwfgoo',\n",
       " 'hawama',\n",
       " 'hawcoo',\n",
       " 'hawcre',\n",
       " 'hawgoo',\n",
       " 'hawhaw',\n",
       " 'hawpet1',\n",
       " 'hoomer',\n",
       " 'houfin',\n",
       " 'houspa',\n",
       " 'hudgod',\n",
       " 'iiwi',\n",
       " 'incter1',\n",
       " 'jabwar',\n",
       " 'japqua',\n",
       " 'kalphe',\n",
       " 'kauama',\n",
       " 'laugul',\n",
       " 'layalb',\n",
       " 'lcspet',\n",
       " 'leasan',\n",
       " 'leater1',\n",
       " 'lessca',\n",
       " 'lesyel',\n",
       " 'lobdow',\n",
       " 'lotjae',\n",
       " 'madpet',\n",
       " 'magpet1',\n",
       " 'mallar3',\n",
       " 'masboo',\n",
       " 'mauala',\n",
       " 'maupar',\n",
       " 'merlin',\n",
       " 'mitpar',\n",
       " 'moudov',\n",
       " 'norcar',\n",
       " 'norhar2',\n",
       " 'normoc',\n",
       " 'norpin',\n",
       " 'norsho',\n",
       " 'nutman',\n",
       " 'oahama',\n",
       " 'omao',\n",
       " 'osprey',\n",
       " 'pagplo',\n",
       " 'palila',\n",
       " 'parjae',\n",
       " 'pecsan',\n",
       " 'peflov',\n",
       " 'perfal',\n",
       " 'pibgre',\n",
       " 'pomjae',\n",
       " 'puaioh',\n",
       " 'reccar',\n",
       " 'redava',\n",
       " 'redjun',\n",
       " 'redpha1',\n",
       " 'refboo',\n",
       " 'rempar',\n",
       " 'rettro',\n",
       " 'ribgul',\n",
       " 'rinduc',\n",
       " 'rinphe',\n",
       " 'rocpig',\n",
       " 'rorpar',\n",
       " 'rudtur',\n",
       " 'ruff',\n",
       " 'saffin',\n",
       " 'sander',\n",
       " 'semplo',\n",
       " 'sheowl',\n",
       " 'shtsan',\n",
       " 'skylar',\n",
       " 'snogoo',\n",
       " 'sooshe',\n",
       " 'sooter1',\n",
       " 'sopsku1',\n",
       " 'sora',\n",
       " 'spodov',\n",
       " 'sposan',\n",
       " 'towsol',\n",
       " 'wantat1',\n",
       " 'warwhe1',\n",
       " 'wesmea',\n",
       " 'wessan',\n",
       " 'wetshe',\n",
       " 'whfibi',\n",
       " 'whiter',\n",
       " 'whttro',\n",
       " 'wiltur',\n",
       " 'yebcar',\n",
       " 'yefcan',\n",
       " 'zebdov']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_mapping = {v: k for k, v in enumerate(mapping)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afrsil1': 0,\n",
       " 'akekee': 1,\n",
       " 'akepa1': 2,\n",
       " 'akiapo': 3,\n",
       " 'akikik': 4,\n",
       " 'amewig': 5,\n",
       " 'aniani': 6,\n",
       " 'apapan': 7,\n",
       " 'arcter': 8,\n",
       " 'barpet': 9,\n",
       " 'bcnher': 10,\n",
       " 'belkin1': 11,\n",
       " 'bkbplo': 12,\n",
       " 'bknsti': 13,\n",
       " 'bkwpet': 14,\n",
       " 'blkfra': 15,\n",
       " 'blknod': 16,\n",
       " 'bongul': 17,\n",
       " 'brant': 18,\n",
       " 'brnboo': 19,\n",
       " 'brnnod': 20,\n",
       " 'brnowl': 21,\n",
       " 'brtcur': 22,\n",
       " 'bubsan': 23,\n",
       " 'buffle': 24,\n",
       " 'bulpet': 25,\n",
       " 'burpar': 26,\n",
       " 'buwtea': 27,\n",
       " 'cacgoo1': 28,\n",
       " 'calqua': 29,\n",
       " 'cangoo': 30,\n",
       " 'canvas': 31,\n",
       " 'caster1': 32,\n",
       " 'categr': 33,\n",
       " 'chbsan': 34,\n",
       " 'chemun': 35,\n",
       " 'chukar': 36,\n",
       " 'cintea': 37,\n",
       " 'comgal1': 38,\n",
       " 'commyn': 39,\n",
       " 'compea': 40,\n",
       " 'comsan': 41,\n",
       " 'comwax': 42,\n",
       " 'coopet': 43,\n",
       " 'crehon': 44,\n",
       " 'dunlin': 45,\n",
       " 'elepai': 46,\n",
       " 'ercfra': 47,\n",
       " 'eurwig': 48,\n",
       " 'fragul': 49,\n",
       " 'gadwal': 50,\n",
       " 'gamqua': 51,\n",
       " 'glwgul': 52,\n",
       " 'gnwtea': 53,\n",
       " 'golphe': 54,\n",
       " 'grbher3': 55,\n",
       " 'grefri': 56,\n",
       " 'gresca': 57,\n",
       " 'gryfra': 58,\n",
       " 'gwfgoo': 59,\n",
       " 'hawama': 60,\n",
       " 'hawcoo': 61,\n",
       " 'hawcre': 62,\n",
       " 'hawgoo': 63,\n",
       " 'hawhaw': 64,\n",
       " 'hawpet1': 65,\n",
       " 'hoomer': 66,\n",
       " 'houfin': 67,\n",
       " 'houspa': 68,\n",
       " 'hudgod': 69,\n",
       " 'iiwi': 70,\n",
       " 'incter1': 71,\n",
       " 'jabwar': 72,\n",
       " 'japqua': 73,\n",
       " 'kalphe': 74,\n",
       " 'kauama': 75,\n",
       " 'laugul': 76,\n",
       " 'layalb': 77,\n",
       " 'lcspet': 78,\n",
       " 'leasan': 79,\n",
       " 'leater1': 80,\n",
       " 'lessca': 81,\n",
       " 'lesyel': 82,\n",
       " 'lobdow': 83,\n",
       " 'lotjae': 84,\n",
       " 'madpet': 85,\n",
       " 'magpet1': 86,\n",
       " 'mallar3': 87,\n",
       " 'masboo': 88,\n",
       " 'mauala': 89,\n",
       " 'maupar': 90,\n",
       " 'merlin': 91,\n",
       " 'mitpar': 92,\n",
       " 'moudov': 93,\n",
       " 'norcar': 94,\n",
       " 'norhar2': 95,\n",
       " 'normoc': 96,\n",
       " 'norpin': 97,\n",
       " 'norsho': 98,\n",
       " 'nutman': 99,\n",
       " 'oahama': 100,\n",
       " 'omao': 101,\n",
       " 'osprey': 102,\n",
       " 'pagplo': 103,\n",
       " 'palila': 104,\n",
       " 'parjae': 105,\n",
       " 'pecsan': 106,\n",
       " 'peflov': 107,\n",
       " 'perfal': 108,\n",
       " 'pibgre': 109,\n",
       " 'pomjae': 110,\n",
       " 'puaioh': 111,\n",
       " 'reccar': 112,\n",
       " 'redava': 113,\n",
       " 'redjun': 114,\n",
       " 'redpha1': 115,\n",
       " 'refboo': 116,\n",
       " 'rempar': 117,\n",
       " 'rettro': 118,\n",
       " 'ribgul': 119,\n",
       " 'rinduc': 120,\n",
       " 'rinphe': 121,\n",
       " 'rocpig': 122,\n",
       " 'rorpar': 123,\n",
       " 'rudtur': 124,\n",
       " 'ruff': 125,\n",
       " 'saffin': 126,\n",
       " 'sander': 127,\n",
       " 'semplo': 128,\n",
       " 'sheowl': 129,\n",
       " 'shtsan': 130,\n",
       " 'skylar': 131,\n",
       " 'snogoo': 132,\n",
       " 'sooshe': 133,\n",
       " 'sooter1': 134,\n",
       " 'sopsku1': 135,\n",
       " 'sora': 136,\n",
       " 'spodov': 137,\n",
       " 'sposan': 138,\n",
       " 'towsol': 139,\n",
       " 'wantat1': 140,\n",
       " 'warwhe1': 141,\n",
       " 'wesmea': 142,\n",
       " 'wessan': 143,\n",
       " 'wetshe': 144,\n",
       " 'whfibi': 145,\n",
       " 'whiter': 146,\n",
       " 'whttro': 147,\n",
       " 'wiltur': 148,\n",
       " 'yebcar': 149,\n",
       " 'yefcan': 150,\n",
       " 'zebdov': 151}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train, test audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.util import find_spec\n",
    "if find_spec(\"bridclef\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    \n",
    "from birdclef.util import get_split_by_bird\n",
    "meta_train, meta_test = get_split_by_bird(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintest_filename = {\"trainval\": list(meta_train.filename), \"test\": list(meta_test.filename)}\n",
    "\n",
    "with open(\"/home/skang/Documents/kaggle/bird_clef/input/birdclef-2022/traintest_filename.json\", \"w\") as f:\n",
    "    json.dump(traintest_filename, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdclef.util import copy_split_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/skang/Documents/kaggle/bird_clef/input/birdclef-2022\"\n",
    "for meta, stage in zip([meta_train, meta_test], [\"trainval\", \"test\"]):\n",
    "    copy_split_audio(meta, root_dir=root_dir, stage=stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/skang/Documents/kaggle/bird_clef/input/birdclef-2022/traintest_filename.json\") as f:\n",
    "    split_names = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11881"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(meta_train.filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11881"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brnowl     500\n",
       "skylar     500\n",
       "norcar     500\n",
       "mallar3    500\n",
       "houspa     500\n",
       "          ... \n",
       "puaioh       3\n",
       "layalb       3\n",
       "akikik       2\n",
       "crehon       2\n",
       "maupar       1\n",
       "Name: primary_label, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.primary_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skylar     401\n",
       "mallar3    400\n",
       "comsan     400\n",
       "norcar     400\n",
       "brnowl     400\n",
       "          ... \n",
       "bkwpet       2\n",
       "akikik       2\n",
       "layalb       2\n",
       "hawhaw       2\n",
       "shtsan       1\n",
       "Name: primary_label, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train.primary_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in meta_train.filename:\n",
    "    if i not in list(meta_df[meta_df.filename.isin(split_names['trainval'])].filename):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2971"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_df[meta_df.filename.isin(split_names['test'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_importpath(package_name: str):\n",
    "    from importlib.util import find_spec\n",
    "    if find_spec(package_name) is None:\n",
    "        import sys\n",
    "        sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_importpath(\"birdclef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skang/.local/share/virtualenvs/kaggle-FCKdAziW/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from birdclef.util import get_output_size_of_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 313)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_in = 256\n",
    "w_in = 313\n",
    "kernel_size = [3, 3]\n",
    "padding = [1, 1]\n",
    "stride = [1, 1]\n",
    "pool = 0\n",
    "get_output_size_of_cnn(h_in, w_in, kernel_size, stride, padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS = \"BCEWithLogitsLoss\"\n",
    "\n",
    "test = getattr(torch.nn, LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0] > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aa, bb, cc'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join([\"aa\", \"bb\", \"cc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/skang/Documents/kaggle/birdclef2022/input/processed/birdclef2022/birdclef2022.json\") as f:\n",
    "    essentials = json.load(f)\n",
    "\n",
    "mapping = list(essentials['birds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0] * len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afrsil1, akiapo'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join([mapping[i] for i in range(len(mapping)) if a[i] == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _audio_to_mel_label(\n",
    "    filepath,\n",
    "    min_sec_proc,\n",
    "    sample_rate,\n",
    "    mel_converter,\n",
    "    stage=\"trainval\",\n",
    "    data_index=0,\n",
    "    label_list=[],\n",
    "    bird_label=[],\n",
    "    label_file=[],\n",
    "):\n",
    "    \"\"\"오디오 파일을 mel spectrogram으로 변환 후 5초 간격으로 잘라서 저장\n",
    "\n",
    "    Args:\n",
    "        filepath (str): 오디오 파일 경로\n",
    "        min_sec_proc (int): 자를 간격(5초) * sample rate\n",
    "        sample_rate (int): 1초에 측정한 샘플 수\n",
    "        mel_converter (torch.transform): mel_converter\n",
    "        data_index (int, optional): 파일이름(인덱스). Defaults to 0.\n",
    "        label_list (list, optional): 각 음원 파일 별 label 정보(target). Defaults to [].\n",
    "        bird_label (list, optional): 전체 타겟 클래스 정보. Defaults to [].\n",
    "        label_file (list, optional): 각 파일에 들어있는 타겟 정보. Defaults to [].\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "\n",
    "    label_file_all = np.zeros(len(bird_label))\n",
    "    for label_file_temp in label_file:\n",
    "        label_file_all += label_file_temp == bird_label\n",
    "    label_file_all = np.clip(label_file_all, 0, 1)\n",
    "\n",
    "    waveform, sample_rate_file = torchaudio.load(filepath=filepath)\n",
    "\n",
    "    if sample_rate_file != sample_rate:\n",
    "        resample = T.Resample(sample_rate_file, sample_rate)\n",
    "        waveform = resample(waveform)\n",
    "\n",
    "    wav_len = waveform.shape[1]\n",
    "    waveform = to_mono(waveform)\n",
    "    waveform = waveform.reshape(1, wav_len)\n",
    "\n",
    "    waveform, wav_len = repeat_crop_waveform(waveform, min_sec_proc, wav_len)\n",
    "\n",
    "    for index in range(int(wav_len / min_sec_proc)):\n",
    "        log_melspec = torch.log10(\n",
    "            mel_converter(\n",
    "                waveform[0, index * min_sec_proc : index * min_sec_proc + min_sec_proc]\n",
    "            ).unsqueeze(0)\n",
    "            + 1e-10\n",
    "        )  # 5초마다 자르기\n",
    "        log_melspec = normalize_std(log_melspec)\n",
    "\n",
    "        if not os.path.exists(PROCESSED_DATA_DIRNAME / stage):\n",
    "            os.makedirs(PROCESSED_DATA_DIRNAME / stage)\n",
    "\n",
    "        torch.save(log_melspec, PROCESSED_DATA_DIRNAME / stage / (str(data_index) + \".pt\"))\n",
    "        label_list.append(label_file_all)\n",
    "        data_index += 1\n",
    "\n",
    "    return data_index\n",
    "\n",
    "\n",
    "def repeat_crop_waveform(waveform: torch.tensor, min_sec_proc, wav_len) -> torch.tensor:\n",
    "    \"\"\"\n",
    "    정해진 길이만큼 오디오를 반복한후 자른다.\n",
    "    \n",
    "    Args:\n",
    "        waveform(torch.tensor): 오디오 파일의 waveform\n",
    "        min_sec : 최소 시간\n",
    "    \"\"\"\n",
    "\n",
    "    if wav_len < min_sec_proc:\n",
    "        for _ in range(round(min_sec_proc / wav_len)):\n",
    "            waveform = torch.cat((waveform, waveform[:, 0:wav_len]), 1)\n",
    "        wav_len = min_sec_proc\n",
    "        waveform = waveform[:, 0:wav_len]\n",
    "\n",
    "    return waveform, wav_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_mel_labels_essentials(\n",
    "    df: pd.DataFrame, stage, min_sec_proc, mel_converter, sample_rate=32000\n",
    "):\n",
    "    \"\"\"audio data를 mel spectrogram으로 변환한 후 5초 간격으로 나누어서 저장.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 오디오 파일 metadata\n",
    "    \"\"\"\n",
    "    if not os.path.exists(PROCESSED_DATA_DIRNAME):\n",
    "        os.makedirs(PROCESSED_DATA_DIRNAME)\n",
    "    bird_label = list(df[\"primary_label\"].unique())\n",
    "    essentials = {\"birds\": bird_label, \"sample_rate\": sample_rate}\n",
    "    with open(ESSENTIALS_FILENAME, \"w\") as f:\n",
    "        json.dump(essentials, f)\n",
    "\n",
    "    data_index = 0\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        data_index = _audio_to_mel_label(\n",
    "            df[\"filepath\"].iloc[i],\n",
    "            min_sec_proc,\n",
    "            sample_rate,\n",
    "            mel_converter,\n",
    "            stage,\n",
    "            data_index,\n",
    "            label_list,\n",
    "            bird_label,\n",
    "            [df[\"primary_label\"].iloc[i]] + eval(df[\"secondary_labels\"].iloc[i]),\n",
    "        )\n",
    "\n",
    "    torch.save(np.stack(label_list), PROCESSED_DATA_DIRNAME / stage / \"label_list.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skang/.local/share/virtualenvs/kaggle-FCKdAziW/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate_file = torchaudio.load(filepath=\"/home/skang/Documents/kaggle/birdclef2022/input/train_audio/afrsil1/XC125458.ogg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 355265])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, wav_len = repeat_crop_waveform(waveform: torch.tensor, 32000 * 5, wavefrom.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.load(\"/home/skang/Documents/kaggle/birdclef2022/input/processed/birdclef2022/v1/trainval/label_list.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ftmlab\\\\Documents\\\\hyoon\\\\project_new\\\\kaggle\\\\birdclef2022\\\\notebook'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "cur = Path(os.path.abspath(os.curdir))\n",
    "import json\n",
    "with open(cur / \"..\" / \"input/processed/birdclef2022/v1/birdclef2022.json\") as f:\n",
    "    essentials = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "output_dim = len(essentials['birds'])\n",
    "y = np.array(essentials['birds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == 'afrsil1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2358309/2551274441.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  print(np.array(t[0]) == 'afrsil1')\n"
     ]
    }
   ],
   "source": [
    "print(np.array(at[0]) == 'afrsil1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afrsil1',\n",
       " 'akekee',\n",
       " 'akepa1',\n",
       " 'akiapo',\n",
       " 'akikik',\n",
       " 'amewig',\n",
       " 'aniani',\n",
       " 'apapan',\n",
       " 'arcter',\n",
       " 'barpet',\n",
       " 'bcnher',\n",
       " 'belkin1',\n",
       " 'bkbplo',\n",
       " 'bknsti',\n",
       " 'bkwpet',\n",
       " 'blkfra',\n",
       " 'blknod',\n",
       " 'bongul',\n",
       " 'brant',\n",
       " 'brnboo',\n",
       " 'brnnod',\n",
       " 'brnowl',\n",
       " 'brtcur',\n",
       " 'bubsan',\n",
       " 'buffle',\n",
       " 'bulpet',\n",
       " 'burpar',\n",
       " 'buwtea',\n",
       " 'cacgoo1',\n",
       " 'calqua',\n",
       " 'cangoo',\n",
       " 'canvas',\n",
       " 'caster1',\n",
       " 'categr',\n",
       " 'chbsan',\n",
       " 'chemun',\n",
       " 'chukar',\n",
       " 'cintea',\n",
       " 'comgal1',\n",
       " 'commyn',\n",
       " 'compea',\n",
       " 'comsan',\n",
       " 'comwax',\n",
       " 'coopet',\n",
       " 'crehon',\n",
       " 'dunlin',\n",
       " 'elepai',\n",
       " 'ercfra',\n",
       " 'eurwig',\n",
       " 'fragul',\n",
       " 'gadwal',\n",
       " 'gamqua',\n",
       " 'glwgul',\n",
       " 'gnwtea',\n",
       " 'golphe',\n",
       " 'grbher3',\n",
       " 'grefri',\n",
       " 'gresca',\n",
       " 'gryfra',\n",
       " 'gwfgoo',\n",
       " 'hawama',\n",
       " 'hawcoo',\n",
       " 'hawcre',\n",
       " 'hawgoo',\n",
       " 'hawhaw',\n",
       " 'hawpet1',\n",
       " 'hoomer',\n",
       " 'houfin',\n",
       " 'houspa',\n",
       " 'hudgod',\n",
       " 'iiwi',\n",
       " 'incter1',\n",
       " 'jabwar',\n",
       " 'japqua',\n",
       " 'kalphe',\n",
       " 'kauama',\n",
       " 'laugul',\n",
       " 'layalb',\n",
       " 'lcspet',\n",
       " 'leasan',\n",
       " 'leater1',\n",
       " 'lessca',\n",
       " 'lesyel',\n",
       " 'lobdow',\n",
       " 'lotjae',\n",
       " 'madpet',\n",
       " 'magpet1',\n",
       " 'mallar3',\n",
       " 'masboo',\n",
       " 'mauala',\n",
       " 'maupar',\n",
       " 'merlin',\n",
       " 'mitpar',\n",
       " 'moudov',\n",
       " 'norcar',\n",
       " 'norhar2',\n",
       " 'normoc',\n",
       " 'norpin',\n",
       " 'norsho',\n",
       " 'nutman',\n",
       " 'oahama',\n",
       " 'omao',\n",
       " 'osprey',\n",
       " 'pagplo',\n",
       " 'palila',\n",
       " 'parjae',\n",
       " 'pecsan',\n",
       " 'peflov',\n",
       " 'perfal',\n",
       " 'pibgre',\n",
       " 'pomjae',\n",
       " 'puaioh',\n",
       " 'reccar',\n",
       " 'redava',\n",
       " 'redjun',\n",
       " 'redpha1',\n",
       " 'refboo',\n",
       " 'rempar',\n",
       " 'rettro',\n",
       " 'ribgul',\n",
       " 'rinduc',\n",
       " 'rinphe',\n",
       " 'rocpig',\n",
       " 'rorpar',\n",
       " 'rudtur',\n",
       " 'ruff',\n",
       " 'saffin',\n",
       " 'sander',\n",
       " 'semplo',\n",
       " 'sheowl',\n",
       " 'shtsan',\n",
       " 'skylar',\n",
       " 'snogoo',\n",
       " 'sooshe',\n",
       " 'sooter1',\n",
       " 'sopsku1',\n",
       " 'sora',\n",
       " 'spodov',\n",
       " 'sposan',\n",
       " 'towsol',\n",
       " 'wantat1',\n",
       " 'warwhe1',\n",
       " 'wesmea',\n",
       " 'wessan',\n",
       " 'wetshe',\n",
       " 'whfibi',\n",
       " 'whiter',\n",
       " 'whttro',\n",
       " 'wiltur',\n",
       " 'yebcar',\n",
       " 'yefcan',\n",
       " 'zebdov']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(\"akekee\" == np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afrsil1', 'houspa', 'redava', 'zebdov']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y[j] for j in range(len(t[0])) if t[2][j] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_SPEC = 128\n",
    "W_SPEC = 313\n",
    "embedding_size = 1024\n",
    "class ResNetBird(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet = torch.nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.pooling = GeM()\n",
    "        o_h, o_w = H_SPEC // 32, W_SPEC // 32 + 1\n",
    "        self.embedding = nn.Linear(512, embedding_size)\n",
    "        self.fc = nn.Linear(embedding_size, output_dim)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.resnet(x)\n",
    "        x = self.pooling(x).flatten(1)\n",
    "        x = self.embedding(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.9904e-01, -8.3791e-01, -1.2619e+00,  9.5162e-02,  9.9783e-01,\n",
       "          6.2090e-01, -9.2301e-01,  1.0538e+00, -5.1902e-02,  2.0504e-01,\n",
       "          8.7513e-01, -5.0454e-01,  1.0899e+00, -9.7472e-01,  5.2867e-01,\n",
       "         -9.3032e-02, -1.3911e+00, -4.6960e-01, -1.3674e-01,  8.0066e-01,\n",
       "         -1.6127e-01, -1.8084e+00,  9.3338e-01, -1.7764e-03, -3.8512e-01,\n",
       "          1.0683e+00, -5.6962e-01, -2.4046e-01,  2.8832e-02,  5.6548e-01,\n",
       "          4.0870e-01, -1.7609e+00, -4.1039e-01,  5.6884e-01,  7.6098e-02,\n",
       "         -7.5229e-01,  3.9971e-01, -9.7782e-01, -1.1542e+00,  5.2280e-01,\n",
       "          1.0622e+00, -3.7133e-01, -3.5100e-02,  9.7366e-01, -1.6001e-01,\n",
       "         -6.1014e-01, -6.4755e-01,  5.4360e-01,  5.3232e-01, -8.8948e-01,\n",
       "          9.9745e-02, -3.8787e-01,  2.2768e-02,  8.8781e-01, -1.8197e+00,\n",
       "          9.9405e-02, -4.2266e-02,  2.8076e-01, -1.4109e+00,  1.0839e+00,\n",
       "          7.5266e-01,  2.0765e-01, -1.2040e-01,  6.1410e-01,  1.3863e-01,\n",
       "          4.3482e-01, -3.3620e-03,  7.1465e-01,  9.1561e-01, -5.0438e-02,\n",
       "          1.6576e-01,  1.5622e-01,  2.7876e-01, -5.2053e-01,  4.3683e-01,\n",
       "         -5.3480e-01,  7.7726e-01, -1.6271e+00,  5.6932e-01,  2.4305e-01,\n",
       "          3.0209e-01, -3.6094e-01, -4.1151e-01,  4.7498e-01, -2.4357e-01,\n",
       "          3.9942e-01,  1.1503e+00,  2.2138e-01,  9.5462e-01,  8.7147e-01,\n",
       "         -1.2104e+00, -2.7351e-02,  1.3324e-01,  2.3393e-02,  8.9646e-01,\n",
       "          8.7054e-01,  5.8216e-01, -3.3037e-02, -3.9309e-02,  3.0594e-01,\n",
       "          1.4585e-01, -2.1506e-01, -2.3188e-01,  7.7185e-02, -2.9986e-01,\n",
       "         -8.6401e-02,  3.0331e-01, -4.7172e-01, -2.5107e-02,  6.6889e-01,\n",
       "         -2.9491e-01,  2.9587e-01,  1.7295e+00,  5.7096e-01,  1.7819e-01,\n",
       "          5.4958e-01,  2.2540e-02, -8.6637e-01,  6.4982e-01,  5.3478e-01,\n",
       "         -3.7288e-01,  1.3752e-01,  1.5146e-01, -4.3851e-01,  2.1406e-01,\n",
       "          4.0806e-01,  9.7894e-01,  7.2592e-01, -9.1424e-02, -2.4421e-01,\n",
       "          1.8808e-01, -6.5182e-01, -1.1793e-01, -6.8183e-01, -4.3832e-01,\n",
       "         -3.2726e-02,  3.3619e-01,  1.3374e-01, -4.8522e-01,  1.0111e+00,\n",
       "          2.2444e-02, -1.6904e-01,  4.0563e-01, -8.4605e-01, -8.9424e-01,\n",
       "          6.7246e-01, -2.8442e-01, -7.7585e-01, -1.0220e+00, -1.3317e+00,\n",
       "         -8.7176e-02, -8.1506e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand((1, 1, H_SPEC, W_SPEC))\n",
    "resnet_bird = ResNetBird()\n",
    "output = resnet_bird(t)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 152])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_SPEC // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_output_size_of_cnn(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    kernel_size: List[int],\n",
    "    stride: List[int],\n",
    "    padding: List[int],\n",
    "    pool=0,\n",
    "    dilation=[1, 1],\n",
    "):\n",
    "    \"\"\"cnn 출력 이미지 크기를 반환한다.\n",
    "    Args:\n",
    "        h_in (int): 입력 이미지 높이\n",
    "        w_in (int): 입력 이미지 너비\n",
    "        kernel_size (List[int, int]): 커널 크기\n",
    "        stride (List[int, int]): 스트라이드\n",
    "        padding (List[int, int]): 패딩\n",
    "        pool (int, optional): 풀링. Defaults to 0.\n",
    "        dilation (list, optional): 커널사이의 간격. Defaults to [1, 1]\n",
    "\n",
    "    Returns:\n",
    "        int: 출력 이미지 크기(h, w)\n",
    "    \"\"\"\n",
    "\n",
    "    h_out = np.floor(\n",
    "        (h_in + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) / stride[0] + 1\n",
    "    )\n",
    "    w_out = np.floor(\n",
    "        (w_in + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) / stride[1] + 1\n",
    "    )\n",
    "\n",
    "    if pool:\n",
    "        h_out /= pool\n",
    "        w_out /= pool\n",
    "\n",
    "    return int(h_out), int(w_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BasicBlock(\n",
       "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): BasicBlock(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_size_of_cnn(h_in=6, w_in=6, stride=[2, 2], padding=[3, 3], kernel_size=[7, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.load(r\"C:\\Users\\ftmlab\\Documents\\hyoon\\project_new\\kaggle\\birdclef2022\\input\\processed\\birdclef2022\\v2\\trainval\\label_list.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203.,   1., 298.,   0.,   0.,  44.,   0., 155.,  23.,   0.,   0.,\n",
       "         0.,   5., 236.,   0.,   0., 156.,   0.,   0., 262.,   0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = np.array([\"a\", \"b\", \"c\", \"d\" \"e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = t[\"c\" == t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c'], dtype='<U2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"a\" == t).sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(t, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "meta = pd.DataFrame(columns=[\"filepath\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftmlab\\AppData\\Local\\Temp\\ipykernel_12736\\2944447012.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  meta = meta.append({\"filepath\": \"aa\", \"label\": [0,1,0,0,0,0]}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "meta = meta.append({\"filepath\": \"aa\", \"label\": [0,1,0,0,0,0]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa</td>\n",
       "      <td>bb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filepath               label\n",
       "0       aa  [0, 1, 0, 0, 0, 0]\n",
       "1       aa  [0, 1, 0, 0, 0, 0]\n",
       "2       aa                  bb"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame([[\"aa\", \"bb\"]], columns=[\"filepath\", \"label\"])\n",
    "pd.concat([meta, t], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = t == \"c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[False, False, True, False]'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.clip(0, 1, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, pd.DataFrame([str(list(test))], columns=[\"label\"])], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0, 0, 1, 0]\n",
       "1    [0, 0, 1, 0]\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label = df.label.map(lambda x: np.array(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [tensor(0), tensor(0), tensor(1), tensor(0)]\n",
       "1    [tensor(0), tensor(0), tensor(1), tensor(0)]\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ftmlab\\Documents\\hyoon\\project_new\\kaggle\\birdclef2022\\input\\processed\\birdclef2022\\v2_test\\trainval\\v2_test_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bird_name\"] = df.filename.map(lambda x: x.split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['others', 'warwhe1', 'iiwi', 'akiapo', 'houfin', 'apapan', 'hawama',\n",
       "       'aniani'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bird_name.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_num = 100\n",
    "birds = df.bird_name.unique()\n",
    "df_new = df\n",
    "for b in birds:\n",
    "    if b == \"others\":\n",
    "        continue\n",
    "    df_new = pd.concat([df_new, df[df.bird_name == b].sample(n=sampling_num, replace=True, ignore_index=True)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "warwhe1    362\n",
       "others     296\n",
       "iiwi       187\n",
       "akiapo     108\n",
       "houfin     105\n",
       "apapan     103\n",
       "hawama     102\n",
       "aniani     101\n",
       "Name: bird_name, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.bird_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.bird_name == \"others\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(df, frac=None):\n",
    "    \n",
    "    df[\"bird_name\"] = df.filename.map(lambda x: x.split(\"/\")[0])\n",
    "    \n",
    "    if frac is None:\n",
    "        frac = max(len(df.bird_name.unique()) - 1, 1)\n",
    "        frac = 1 / frac\n",
    "    \n",
    "    sampling_num = int(len(df[df.bird_name == \"others\"]) * frac)\n",
    "    birds = df.bird_name.unique()\n",
    "    df_new = df\n",
    "    for b in birds:\n",
    "        if b == \"others\":\n",
    "            continue\n",
    "        df_new = pd.concat([df_new, df[df.bird_name == b].sample(n=sampling_num, replace=True, ignore_index=True)], ignore_index=True)\n",
    "    # print(\"Before oversampling\")\n",
    "    # print(df.bird_name.value_counts())\n",
    "    # print(\"After oversampling\")\n",
    "    # print(df_new.bird_name.value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before oversampling\n",
      "others     296\n",
      "warwhe1    262\n",
      "iiwi        87\n",
      "akiapo       8\n",
      "houfin       5\n",
      "apapan       3\n",
      "hawama       2\n",
      "aniani       1\n",
      "Name: bird_name, dtype: int64\n",
      "After oversampling\n",
      "warwhe1    304\n",
      "others     296\n",
      "iiwi       129\n",
      "akiapo      50\n",
      "houfin      47\n",
      "apapan      45\n",
      "hawama      44\n",
      "aniani      43\n",
      "Name: bird_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ftmlab\\Documents\\hyoon\\project_new\\kaggle\\birdclef2022\\input\\processed\\birdclef2022\\v2_test\\trainval\\v2_test_meta.csv\")\n",
    "df = oversampling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\ftmlab\\Documents\\hyoon\\project_new\\kaggle\\birdclef2022\\input\\processed\\birdclef2022\\v3_test\\trainval\\v3_test_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bird_name\"] = df.filename.map(lambda x: x.split(\"/\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df[\"bird_name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filepath'] = input_path + \"/\" + df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'afrsil1'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filepath[0].rsplit(\".\", 1)[0].rsplit(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../input/birdclef-2022/train_audio/afrsil1/fc8db52e-690d-4b0a-af87-e8a2b7702ccf')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(df.filepath[0].rsplit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 2 , 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.tensor([False, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[t.argmax()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"C:\\Users\\ftmlab\\Documents\\hyoon\\project_new\\kaggle\\birdclef2022\\input\\birdclef-2022\\scored_birds.json\") as f:\n",
    "    t = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiapo',\n",
       " 'aniani',\n",
       " 'apapan',\n",
       " 'barpet',\n",
       " 'crehon',\n",
       " 'elepai',\n",
       " 'ercfra',\n",
       " 'hawama',\n",
       " 'hawcre',\n",
       " 'hawgoo',\n",
       " 'hawhaw',\n",
       " 'hawpet1',\n",
       " 'houfin',\n",
       " 'iiwi',\n",
       " 'jabwar',\n",
       " 'maupar',\n",
       " 'omao',\n",
       " 'puaioh',\n",
       " 'skylar',\n",
       " 'warwhe1',\n",
       " 'yefcan']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "65d8178cd94985c4dcbe616260cbccd0fc074a8ce1c02a7f35275946c8a6c26e"
  },
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
