{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"practice EDA to prediction\n\nrefer to\n\nhttps://www.kaggle.com/code/shreyasajal/birdclef-librosa-audio-feature-extraction/notebook\nhttps://www.kaggle.com/code/utcarshagrawal/birdclef-audio-pytorch-tutorial","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-10T06:47:34.637285Z","iopub.execute_input":"2022-05-10T06:47:34.638311Z","iopub.status.idle":"2022-05-10T06:47:34.666132Z","shell.execute_reply.started":"2022-05-10T06:47:34.638173Z","shell.execute_reply":"2022-05-10T06:47:34.665509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torchaudio\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport sklearn\nimport warnings\nimport seaborn as sns\nfrom typing import List\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:34.967784Z","iopub.execute_input":"2022-05-10T06:47:34.968471Z","iopub.status.idle":"2022-05-10T06:47:40.478306Z","shell.execute_reply.started":"2022-05-10T06:47:34.968432Z","shell.execute_reply":"2022-05-10T06:47:40.477207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOTDIR = '../input/birdclef-2022'","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.480091Z","iopub.execute_input":"2022-05-10T06:47:40.480767Z","iopub.status.idle":"2022-05-10T06:47:40.485368Z","shell.execute_reply.started":"2022-05-10T06:47:40.480716Z","shell.execute_reply":"2022-05-10T06:47:40.484414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv('../input/birdclef-2022/train_metadata.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.486598Z","iopub.execute_input":"2022-05-10T06:47:40.486884Z","iopub.status.idle":"2022-05-10T06:47:40.636841Z","shell.execute_reply.started":"2022-05-10T06:47:40.486843Z","shell.execute_reply":"2022-05-10T06:47:40.636019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# sampling and play","metadata":{}},{"cell_type":"code","source":"class AudioP():\n    def __init__(self):\n        self.root_dir = ROOTDIR\n        # edit metadata\n        self.meta = pd.read_csv(fr\"{self.root_dir}/train_metadata.csv\")\n        self.meta[\"full_path\"] = self.root_dir + '/' + 'train_audio' + '/' + self.meta['filename']\n        \n    \n    def get_random_sample_by_feature(self, key: str = 'primary', value: str = None, random_state: int = 33):\n        \"\"\"\n        get random audio links by feature\n        \"\"\"\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        return audio\n    \n    \n    def play_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        print(f\"{key}: {value}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    def play_sample_by_idx(self, idx: int = None, feature: str = 'primary_label'):\n        audio = self.meta['full_path'].values[idx]\n        print(f\"{feature}: {self.meta[feature].values[idx]}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    @staticmethod\n    def play_sample(file_path):\n        return ipd.display(ipd.Audio(file_path)) # ipd.Audio(audio)\n    \n    \ntest_d = AudioP()\nbirds = list(train_df.primary_label.unique()[0:6])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.63936Z","iopub.execute_input":"2022-05-10T06:47:40.640042Z","iopub.status.idle":"2022-05-10T06:47:40.734387Z","shell.execute_reply.started":"2022-05-10T06:47:40.639994Z","shell.execute_reply":"2022-05-10T06:47:40.733557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## sampling","metadata":{}},{"cell_type":"code","source":"audios = []\nfor b in birds:\n    audios.append(test_d.get_random_sample_by_feature(**{'key': 'primary_label', 'value': b}))\n\nfor a in audios:\n    print(a)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.736313Z","iopub.execute_input":"2022-05-10T06:47:40.7368Z","iopub.status.idle":"2022-05-10T06:47:40.774805Z","shell.execute_reply.started":"2022-05-10T06:47:40.736756Z","shell.execute_reply":"2022-05-10T06:47:40.773883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a, b in zip(audios, birds):\n    print(f\"{b}\")\n    test_d.play_sample(a)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.776293Z","iopub.execute_input":"2022-05-10T06:47:40.776564Z","iopub.status.idle":"2022-05-10T06:47:40.877115Z","shell.execute_reply.started":"2022-05-10T06:47:40.776535Z","shell.execute_reply":"2022-05-10T06:47:40.876539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for b in birds:\n    test_d.play_random_sample_by_feature(**{'key': 'primary_label', 'value': b})","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.87809Z","iopub.execute_input":"2022-05-10T06:47:40.878796Z","iopub.status.idle":"2022-05-10T06:47:40.950719Z","shell.execute_reply.started":"2022-05-10T06:47:40.878758Z","shell.execute_reply":"2022-05-10T06:47:40.94983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading and visualizing an audio file","metadata":{}},{"cell_type":"markdown","source":"- librosa.load: loads an audio file as a floating point time series and gives it's native sampling rate.\n- The sampling frequency (or sample rate) is the number of samples (data points) per second in an audio.\n- We can check the audio length by dividing the total number of data points by the sampling frequency.","metadata":{}},{"cell_type":"code","source":"class AudioLibrosa():\n    def __init__(self):\n        self.root_dir = ROOTDIR\n        # edit metadata\n        self.meta = pd.read_csv(fr\"{self.root_dir}/train_metadata.csv\")\n        self.meta[\"full_path\"] = self.root_dir + '/' + 'train_audio' + '/' + self.meta['filename']\n        \n    \n    def get_random_sample_by_feature(self, key: str = 'primary', value: str = None, random_state: int = 33):\n        \"\"\"\n        get random audio links by feature\n        \"\"\"\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        return audio\n        \n        \n    def play_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        print(f\"{key}: {value}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    def play_sample_by_idx(self, idx: int = None, feature: str = 'primary_label'):\n        audio = self.meta['full_path'].values[idx]\n        print(f\"{feature}: {self.meta[feature].values[idx]}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n\n\n    @staticmethod\n    def play_sample(file_path):\n        return ipd.display(ipd.Audio(file_path)) # ipd.Audio(audio)\n    \n    \n    def load_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33, trim=True):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        y, sr = librosa.load(audio)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n\n    \n    def load_sample_by_idx(self, idx, trim=True):\n        y, sr = librosa.load(self.meta['full_path'].values[idx])\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    @staticmethod\n    def load_sample(file_path, trim=True):\n        y, sr = librosa.load(file_path)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \ntest_d = AudioLibrosa()\nbirds = list(train_df.primary_label.unique()[0:6])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:47:40.952238Z","iopub.execute_input":"2022-05-10T06:47:40.952485Z","iopub.status.idle":"2022-05-10T06:47:41.052896Z","shell.execute_reply.started":"2022-05-10T06:47:40.952455Z","shell.execute_reply":"2022-05-10T06:47:41.051992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Trimming the leading and trailing silence","metadata":{}},{"cell_type":"code","source":"trimed_samples = []\nsample_rates = []\nfor a in audios:\n    audio_file, sr = test_d.load_sample(a)\n    trimed_samples.append(audio_file)\n    sample_rates.append(sr)\n    print('Audio File:', audio_file, '\\n')\n    print('Audio File shape:', np.shape(audio_file))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:52:47.976309Z","iopub.execute_input":"2022-05-10T06:52:47.977408Z","iopub.status.idle":"2022-05-10T06:52:53.081896Z","shell.execute_reply.started":"2022-05-10T06:52:47.977327Z","shell.execute_reply":"2022-05-10T06:52:53.080957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Time domain features","metadata":{}},{"cell_type":"markdown","source":"## Waveform visualization","metadata":{}},{"cell_type":"code","source":"class AudioLibrosa():\n    def __init__(self):\n        self.root_dir = ROOTDIR\n        # edit metadata\n        self.meta = pd.read_csv(fr\"{self.root_dir}/train_metadata.csv\")\n        self.meta[\"full_path\"] = self.root_dir + '/' + 'train_audio' + '/' + self.meta['filename']\n        \n    \n    def get_random_sample_by_feature(self, key: str = 'primary', value: str = None, random_state: int = 33):\n        \"\"\"\n        get random audio links by feature\n        \"\"\"\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        return audio\n        \n        \n    def play_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        print(f\"{key}: {value}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    def play_sample_by_idx(self, idx: int = None, feature: str = 'primary_label'):\n        audio = self.meta['full_path'].values[idx]\n        print(f\"{feature}: {self.meta[feature].values[idx]}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n\n\n    @staticmethod\n    def play_sample(file_path):\n        return ipd.display(ipd.Audio(file_path)) # ipd.Audio(audio)\n    \n    \n    def load_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33, trim=True):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        y, sr = librosa.load(audio)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n\n    \n    def load_sample_by_idx(self, idx, trim=True):\n        y, sr = librosa.load(self.meta['full_path'].values[idx])\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    @staticmethod\n    def load_sample(file_path, trim=True):\n        y, sr = librosa.load(file_path)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    @staticmethod\n    def waveplot(samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        \"\"\"\n        colorlist : [\"#A300F9\", \"#4300FF\", \"#009DFF\", \"#00FFB0\", \"#D9FF00\", \"r\"]\n        \"\"\"\n        colors = [\"#009DFF\", \"#A300F9\", \"#4300FF\", \"#00FFB0\", \"#D9FF00\", \"r\"]\n        \n        if not isinstance(samples, list):\n            samples = [samples]\n            \n        if not isinstance(sample_rates, list):\n            sample_rates = [sample_rates]\n            \n        if names and not isinstance(names, list):\n            names = [names]\n        \n        if len(samples) == 1:\n            sample = samples[0]\n            sr = sample_rates[0]\n            \n            fig, ax = plt.subplots(1, figsize = (16, 3))\n            fig.suptitle('Sound Waves', fontsize=16)\n            librosa.display.waveshow(y=sample, sr=sr, color=colors[0], ax=ax)\n            \n            if names:\n                name = names[0]\n                ax.set_ylabel(name, fontsize=13)\n            \n        elif len(samples) > 1:\n            n = len(samples)\n            fig, ax = plt.subplots(n, figsize = (16, 3*n))\n            fig.suptitle('Sound Waves', fontsize=16)\n            \n            for i in range(len(samples)):\n                librosa.display.waveshow(y=samples[i], sr=sample_rates[i], color=colors[i % 6], ax=ax[i])\n                \n                if names:\n                    ax[i].set_ylabel(names[i], fontsize=13)\n        else:\n            print(\"samples need to contain more than one\")\n            assert len(samples) >= 1\n        \n    \ntest_d = AudioLibrosa()\nbirds = list(train_df.primary_label.unique()[0:6])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:57:31.575768Z","iopub.execute_input":"2022-05-10T06:57:31.576146Z","iopub.status.idle":"2022-05-10T06:57:31.702511Z","shell.execute_reply.started":"2022-05-10T06:57:31.576111Z","shell.execute_reply":"2022-05-10T06:57:31.701415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_d.waveplot(trimed_samples, sample_rates, names=birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T06:57:47.161146Z","iopub.execute_input":"2022-05-10T06:57:47.162469Z","iopub.status.idle":"2022-05-10T06:57:52.284474Z","shell.execute_reply.started":"2022-05-10T06:57:47.162405Z","shell.execute_reply":"2022-05-10T06:57:52.283608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Spectrogram","metadata":{}},{"cell_type":"code","source":"class Config:\n    n_fft=2048\n    hop_length=512","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:03:52.350705Z","iopub.execute_input":"2022-05-10T08:03:52.351106Z","iopub.status.idle":"2022-05-10T08:03:52.355507Z","shell.execute_reply.started":"2022-05-10T08:03:52.351077Z","shell.execute_reply":"2022-05-10T08:03:52.354776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AudioLibrosa():\n    def __init__(self, meta: pd.DataFrame: None, n_fft: int = 1024, hop_length: int = 512):\n        self.meta = meta\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.colors = [\"#009DFF\", \"#A300F9\", \"#4300FF\", \"#00FFB0\", \"#D9FF00\", \"r\"]\n    \n    \n    # get random sample by feature\n    def get_random_sample_by_feature(self, key: str = 'primary', value: str = None, random_state: int = 33):\n        \"\"\"\n        get random audio links by feature\n        \"\"\"\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        return audio\n        \n    \n    # play sound\n    def play_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        print(f\"{key}: {value}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    def play_sample_by_idx(self, idx: int = None, feature: str = 'primary_label'):\n        audio = self.meta['full_path'].values[idx]\n        print(f\"{feature}: {self.meta[feature].values[idx]}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n\n\n    def play_sample(self, file_path):\n        return ipd.display(ipd.Audio(file_path)) # ipd.Audio(audio)\n    \n    \n    # get sample, sr\n    def load_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33, trim=True):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        y, sr = librosa.load(audio)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n\n    \n    def load_sample_by_idx(self, idx, trim=True):\n        y, sr = librosa.load(self.meta['full_path'].values[idx])\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    def load_sample(self, file_path, trim=True):\n        y, sr = librosa.load(file_path)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    # plot waveform\n    def waveplot(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        \"\"\"\n        \"\"\"\n        \n        if not isinstance(samples, list):\n            samples = [samples]\n            \n        if not isinstance(sample_rates, list):\n            sample_rates = [sample_rates]\n            \n        if names and not isinstance(names, list):\n            names = [names]\n        \n        if len(samples) == 1:\n            sample = samples[0]\n            sr = sample_rates[0]\n            \n            fig, ax = plt.subplots(1, figsize = (16, 3))\n            fig.suptitle('Sound Waves', fontsize=16)\n            librosa.display.waveshow(y=sample, sr=sr, color=self.colors[0], ax=ax)\n            \n            if names:\n                name = names[0]\n                ax.set_ylabel(name, fontsize=13)\n            \n        elif len(samples) > 1:\n            n = len(samples)\n            fig, ax = plt.subplots(n, figsize = (16, 3*n))\n            fig.suptitle('Sound Waves', fontsize=16)\n            \n            for i in range(len(samples)):\n                librosa.display.waveshow(y=samples[i], sr=sample_rates[i], color=self.colors[i % 6], ax=ax[i])\n                \n                if names:\n                    ax[i].set_ylabel(names[i], fontsize=13)\n        else:\n            print(\"samples need to contain more than one\")\n            assert len(samples) >= 1\n            \n            \n    def wave_plot_by_idx(self, idx, trim=True, feature: str = \"primary_label\"):\n        \"\"\"\n        \"\"\"\n        \n        y, sr = self.load_sample_by_idx(idx, trim=trim)\n            \n        fig, ax = plt.subplots(1, figsize = (16, 3))\n        fig.suptitle('Sound Waves', fontsize=16)\n        librosa.display.waveshow(y=y, sr=sr, color=self.colors[0], ax=ax)\n        \n        name = self.meta[feature].values[idx]\n        ax.set_ylabel(name, fontsize=13)\n            \n    \n    # plot spectrogram\n    def spectrogram(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        \"\"\"\n        \"\"\"\n        \n        if not isinstance(samples, list):\n            samples = [samples]\n            \n        if not isinstance(sample_rates, list):\n            sample_rates = [sample_rates]\n            \n        if names and not isinstance(names, list):\n            names = [names]\n            \n        if len(samples) == 1:\n            # Short-time Fourier transform (STFT)\n            stft = np.abs(librosa.stft(samples[0], n_fft=self.n_fft, hop_length=self.hop_length))\n            # Convert an amplitude spectrogram to Decibels-scaled spectrogram.\n            DB_spec = librosa.amplitude_to_db(stft, ref = np.max)\n            \n            # === PLOT ===\n            fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n            fig.suptitle('Log Frequency Spectrogram', fontsize=16)\n            # fig.delaxes(ax[1, 2])\n            \n            img=librosa.display.specshow(DB_spec, sr=sample_rates[0], hop_length=self.hop_length, x_axis = 'time',\n                         y_axis = 'log', cmap = 'cool', ax=ax)\n            ax.set_title(names[0], fontsize=13) \n            plt.colorbar(img,ax=ax)\n            \n        elif len(samples) > 1:\n            n = len(samples)\n            fig, ax = plt.subplots(n, figsize = (16, 6*n))\n            fig.suptitle('Log Frequency Spectrogram', fontsize=16)\n            \n            for i in range(len(samples)):\n                stft = np.abs(librosa.stft(samples[i], n_fft=self.n_fft, hop_length=self.hop_length))\n                # Convert an amplitude spectrogram to Decibels-scaled spectrogram.\n                DB_spec = librosa.amplitude_to_db(stft, ref = np.max)\n                \n                img=librosa.display.specshow(DB_spec, sr=sample_rates[i], hop_length=self.hop_length, x_axis = 'time',\n                         y_axis = 'log', cmap = 'cool', ax=ax[i])\n                \n                if names:\n                    ax[i].set_title(names[i], fontsize=13)\n            \n        \n        else:\n            print(\"samples need to contain more than one\")\n            assert len(samples) >= 1\n            \n        \n    def plot_rmse(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        S, phase = librosa.magphase(librosa.stft(samples))\n        S_db=librosa.amplitude_to_db(S, ref=np.max)\n        rms = librosa.feature.rms(S=S)\n        fig, ax = plt.subplots(nrows=2, sharex=True,figsize = (16, 6))\n        times = librosa.times_like(rms)\n        ax[0].semilogy(times, rms[0], label='RMS Energy')\n        ax[0].set(xticks=[])\n        ax[0].legend()\n        ax[0].label_outer()\n        librosa.display.specshow(S_db,\n                                 y_axis='log', x_axis='time', ax=ax[1])\n        ax[1].set(title='log Power spectrogram')\n        plt.show()\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AudioLibrosa():\n    def __init__(self, n_fft, hop_length):\n        self.root_dir = ROOTDIR\n        # edit metadata\n        self.meta = pd.read_csv(fr\"{self.root_dir}/train_metadata.csv\")\n        self.meta[\"full_path\"] = self.root_dir + '/' + 'train_audio' + '/' + self.meta['filename']\n        self.n_fft = n_fft\n        self.hop_length = hop_length\n        self.colors = [\"#009DFF\", \"#A300F9\", \"#4300FF\", \"#00FFB0\", \"#D9FF00\", \"r\"]\n    \n    # get random sample by feature\n    def get_random_sample_by_feature(self, key: str = 'primary', value: str = None, random_state: int = 33):\n        \"\"\"\n        get random audio links by feature\n        \"\"\"\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        return audio\n        \n    \n    # play sound\n    def play_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        print(f\"{key}: {value}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n    \n    \n    def play_sample_by_idx(self, idx: int = None, feature: str = 'primary_label'):\n        audio = self.meta['full_path'].values[idx]\n        print(f\"{feature}: {self.meta[feature].values[idx]}\")\n        return ipd.display(ipd.Audio(audio)) # ipd.Audio(audio)\n\n\n    def play_sample(self, file_path):\n        return ipd.display(ipd.Audio(file_path)) # ipd.Audio(audio)\n    \n    \n    # get sample, sr\n    def load_random_sample_by_feature(self, key: str = None, value: str = None, random_state: int = 33, trim=True):\n        audio = self.meta[self.meta[key] == value].sample(1, random_state = 33)['full_path'].values[0]\n        y, sr = librosa.load(audio)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n\n    \n    def load_sample_by_idx(self, idx, trim=True):\n        y, sr = librosa.load(self.meta['full_path'].values[idx])\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    def load_sample(self, file_path, trim=True):\n        y, sr = librosa.load(file_path)\n        \n        if trim:\n            y, _ = librosa.effects.trim(y)\n            \n        return y, sr\n    \n    \n    # plot waveform\n    def waveplot(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        \"\"\"\n        \"\"\"\n        \n        if not isinstance(samples, list):\n            samples = [samples]\n            \n        if not isinstance(sample_rates, list):\n            sample_rates = [sample_rates]\n            \n        if names and not isinstance(names, list):\n            names = [names]\n        \n        if len(samples) == 1:\n            sample = samples[0]\n            sr = sample_rates[0]\n            \n            fig, ax = plt.subplots(1, figsize = (16, 3))\n            fig.suptitle('Sound Waves', fontsize=16)\n            librosa.display.waveshow(y=sample, sr=sr, color=self.colors[0], ax=ax)\n            \n            if names:\n                name = names[0]\n                ax.set_ylabel(name, fontsize=13)\n            \n        elif len(samples) > 1:\n            n = len(samples)\n            fig, ax = plt.subplots(n, figsize = (16, 3*n))\n            fig.suptitle('Sound Waves', fontsize=16)\n            \n            for i in range(len(samples)):\n                librosa.display.waveshow(y=samples[i], sr=sample_rates[i], color=self.colors[i % 6], ax=ax[i])\n                \n                if names:\n                    ax[i].set_ylabel(names[i], fontsize=13)\n        else:\n            print(\"samples need to contain more than one\")\n            assert len(samples) >= 1\n            \n            \n    def wave_plot_by_idx(self, idx, trim=True, feature: str = \"primary_label\"):\n        \"\"\"\n        \"\"\"\n        \n        y, sr = self.load_sample_by_idx(idx, trim=trim)\n            \n        fig, ax = plt.subplots(1, figsize = (16, 3))\n        fig.suptitle('Sound Waves', fontsize=16)\n        librosa.display.waveshow(y=y, sr=sr, color=self.colors[0], ax=ax)\n        \n        name = self.meta[feature].values[idx]\n        ax.set_ylabel(name, fontsize=13)\n            \n    \n    # plot spectrogram\n    def spectrogram(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        \"\"\"\n        \"\"\"\n        \n        if not isinstance(samples, list):\n            samples = [samples]\n            \n        if not isinstance(sample_rates, list):\n            sample_rates = [sample_rates]\n            \n        if names and not isinstance(names, list):\n            names = [names]\n            \n        if len(samples) == 1:\n            # Short-time Fourier transform (STFT)\n            stft = np.abs(librosa.stft(samples[0], n_fft=self.n_fft, hop_length=self.hop_length))\n            # Convert an amplitude spectrogram to Decibels-scaled spectrogram.\n            DB_spec = librosa.amplitude_to_db(stft, ref = np.max)\n            \n            # === PLOT ===\n            fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n            fig.suptitle('Log Frequency Spectrogram', fontsize=16)\n            # fig.delaxes(ax[1, 2])\n            \n            img=librosa.display.specshow(DB_spec, sr=sample_rates[0], hop_length=self.hop_length, x_axis = 'time',\n                         y_axis = 'log', cmap = 'cool', ax=ax)\n            ax.set_title(names[0], fontsize=13) \n            plt.colorbar(img,ax=ax)\n            \n        elif len(samples) > 1:\n            n = len(samples)\n            fig, ax = plt.subplots(n, figsize = (16, 6*n))\n            fig.suptitle('Log Frequency Spectrogram', fontsize=16)\n            \n            for i in range(len(samples)):\n                stft = np.abs(librosa.stft(samples[i], n_fft=self.n_fft, hop_length=self.hop_length))\n                # Convert an amplitude spectrogram to Decibels-scaled spectrogram.\n                DB_spec = librosa.amplitude_to_db(stft, ref = np.max)\n                \n                img=librosa.display.specshow(DB_spec, sr=sample_rates[i], hop_length=self.hop_length, x_axis = 'time',\n                         y_axis = 'log', cmap = 'cool', ax=ax[i])\n                \n                if names:\n                    ax[i].set_title(names[i], fontsize=13)\n            \n        \n        else:\n            print(\"samples need to contain more than one\")\n            assert len(samples) >= 1\n            \n        \n    def plot_rmse(self, samples: List[np.ndarray], sample_rates: List[str], names: List[str] = None):\n        S, phase = librosa.magphase(librosa.stft(samples))\n        S_db=librosa.amplitude_to_db(S, ref=np.max)\n        rms = librosa.feature.rms(S=S)\n        fig, ax = plt.subplots(nrows=2, sharex=True,figsize = (16, 6))\n        times = librosa.times_like(rms)\n        ax[0].semilogy(times, rms[0], label='RMS Energy')\n        ax[0].set(xticks=[])\n        ax[0].legend()\n        ax[0].label_outer()\n        librosa.display.specshow(S_db,\n                                 y_axis='log', x_axis='time', ax=ax[1])\n        ax[1].set(title='log Power spectrogram')\n        plt.show()\n        \n    \ntest_d = AudioLibrosa(n_fft=Config.n_fft, hop_length=Config.hop_length)\nbirds = list(train_df.primary_label.unique()[0:6])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:21:48.817636Z","iopub.execute_input":"2022-05-10T08:21:48.818036Z","iopub.status.idle":"2022-05-10T08:21:48.9675Z","shell.execute_reply.started":"2022-05-10T08:21:48.817998Z","shell.execute_reply":"2022-05-10T08:21:48.966239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_d.spectrogram(trimed_samples, sample_rates, birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:21:49.406913Z","iopub.execute_input":"2022-05-10T08:21:49.407266Z","iopub.status.idle":"2022-05-10T08:21:56.937183Z","shell.execute_reply.started":"2022-05-10T08:21:49.40723Z","shell.execute_reply":"2022-05-10T08:21:56.936268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}